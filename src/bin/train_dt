import argparse
import gymnasium as gym
from simpledt.collect import collect_rollout

from simpledt.models.dtpolicy import DTPolicy
from simpledt.replay_buffer import ReplayBuffer


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("--env", type=str, default="Pendulum-v1")
    parser.add_argument("--hidden-size", type=int, default=32)
    parser.add_argument("--num-layers", type=int, default=2)
    parser.add_argument("--nhead", type=int, default=4)
    parser.add_argument("--dim-feedforward", type=int, default=32)
    # parser.add_argument("--output-seq-len", type=int, default=10)
    parser.add_argument("--max-steps", type=int, default=100)
    parser.add_argument("--num-rollouts-per-epoch", type=int, default=10)
    # parser.add_argument("--max-size", type=int, default=1000)
    parser.add_argument("--num-epochs", type=int, default=1)
    return parser.parse_args()


def main():
    # Parse the command-line arguments
    args = parse_args()

    # Create the environment and the policy
    env = gym.make(args.env)
    env_render = gym.make(args.env, render_mode="human")
    obs_size = env.observation_space.shape[0]
    action_size = env.action_space.shape[0]
    policy = DTPolicy(
        obs_size,
        action_size,
        hidden_size=args.hidden_size,
        num_layers=args.num_layers,
        nhead=args.nhead,
        dim_feedforward=args.dim_feedforward,
        output_seq_len=args.max_steps,
        batch_first=True,
        device="cpu",
    )

    # Create the replay buffer
    observation_shape = {"observation": (obs_size,)}
    action_shape = (action_size,)
    info_shape = {}
    replay_buffer = ReplayBuffer(
        max_size=args.num_rollouts_per_epoch,
        rollout_len=args.max_steps,
        observation_shape=observation_shape,
        action_shape=action_shape,
        info_shape=info_shape,
    )

    # Collect rollouts and put them into the replay buffer
    for epoch in range(args.num_epochs):
        for i in range(args.num_rollouts_per_epoch):
            rollout = collect_rollout(env_render if i == 0 else env, policy, args.max_steps)
            rollout.observations = {"observation": rollout.observations}
            replay_buffer.add_rollout(rollout)


if __name__ == "__main__":
    main()
